{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odia Word Embeddings Evaluation\n",
    "\n",
    "This notebook helps you evaluate and visualize Odia word embeddings trained with Word2Vec and GloVe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if running in a fresh environment\n",
    "# !pip install gensim numpy pandas matplotlib scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model loaded!\n",
      "Word2Vec_sg model loaded!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "w2v_path = '../models/word2vec.model'\n",
    "if os.path.exists(w2v_path):\n",
    "    w2v_model = Word2Vec.load(w2v_path)\n",
    "    print('Word2Vec model loaded!')\n",
    "else:\n",
    "    print('Word2Vec model not found!')\n",
    "\n",
    "w2vsg_path = '../models/word2vec_sg.model'\n",
    "if os.path.exists(w2v_path):\n",
    "    w2vsg_model = Word2Vec.load(w2vsg_path)\n",
    "    print('Word2Vec_sg model loaded!')\n",
    "else:\n",
    "    print('Word2Vec_sg model not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "glove_emb_path = '../models/glove_embeddings.npy'\n",
    "glove_vocab_path = '../models/glove_vocab.json'\n",
    "if os.path.exists(glove_emb_path) and os.path.exists(glove_vocab_path):\n",
    "    glove_embeddings = np.load(glove_emb_path)\n",
    "    with open(glove_vocab_path, 'r', encoding='utf-8') as f:\n",
    "        glove_vocab = json.load(f)\n",
    "    print('GloVe embeddings loaded!')\n",
    "else:\n",
    "    print('GloVe embeddings not found!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors (Word2Vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to ଭଲ:\n",
      "  ଖରାପ: 0.5172\n",
      "  ସହଜ: 0.4499\n",
      "  ଖୁସି: 0.4427\n",
      "  ନିଶ୍ଚିତ: 0.4412\n",
      "  ବଡ଼: 0.4389\n",
      "Words similar to ମନ୍ଦ:\n",
      "  ଲାଗୁନାହିଁ: 0.5991\n",
      "  ପାଉଥିଲି: 0.5783\n",
      "  ଲାଗିବ୤: 0.5746\n",
      "  ବୁଝିବା: 0.5681\n",
      "  ଜରାରୋଗ: 0.5467\n",
      "Words similar to ପ୍ରେମ:\n",
      "  ଅନାବିଳ: 0.6509\n",
      "  ପ୍ରେମିକା: 0.6298\n",
      "  ସ୍ନେହ: 0.6243\n",
      "  ଆବେଗ: 0.6104\n",
      "  ପ୍ରୀତି: 0.6099\n",
      "Words similar to ଘୃଣା:\n",
      "  ଉପହାସ: 0.7648\n",
      "  ଭୟ: 0.7437\n",
      "  ଈର୍ଷା: 0.7320\n",
      "  ପ୍ରତିବାଦ: 0.7018\n",
      "  ହତାଦର: 0.7011\n",
      "Words similar to ଶିକ୍ଷା:\n",
      "  ଶିକ୍ଷ୍ୟା: 0.6877\n",
      "  ବିଦ୍ୟା: 0.6349\n",
      "  ଉଚ୍ଚଶିକ୍ଷା: 0.6348\n",
      "  ଗଣିତ: 0.6232\n",
      "  ତାଲିମ: 0.6125\n",
      "Words similar to ଗ୍ରାମ:\n",
      "  ତହସିଲ: 0.6835\n",
      "  ଗ୍ରାମରୁ: 0.6628\n",
      "  ବ୍ଲକ: 0.6588\n",
      "  ଥାନା: 0.6482\n",
      "  ସହର: 0.6467\n",
      "Words similar to ନଗର:\n",
      "  ଜୟପୁର: 0.7284\n",
      "  ମଥୁରା: 0.7102\n",
      "  କାନପୁର: 0.7065\n",
      "  ବାରଣାସୀ: 0.7030\n",
      "  ଉତ୍ତରପ୍ରଦେଶ: 0.7027\n",
      "Words similar to ପାଣି:\n",
      "  ପାଣିରେ: 0.6755\n",
      "  କ୍ଷୀର: 0.6646\n",
      "  ଚିନି: 0.6448\n",
      "  ତେଲ: 0.6447\n",
      "  ବାମ୍ଫ: 0.6403\n",
      "Words similar to ଅଗ୍ନି:\n",
      "  ଦେବତାଙ୍କର: 0.6402\n",
      "  ସୂର୍ଯ୍ୟ: 0.6254\n",
      "  ଗ୍ରହ: 0.6251\n",
      "  ପୁଷ୍କରିଣୀର: 0.6113\n",
      "  ବୃହସ୍ପତି: 0.6009\n",
      "Words similar to ବାୟୁ:\n",
      "  ପ୍ରଦୂଷଣ: 0.7545\n",
      "  ପ୍ରବାହ: 0.7445\n",
      "  ଗ୍ୟାସ୍: 0.7250\n",
      "  ଯବକ୍ଷାରଜାନ: 0.7061\n",
      "  ବାୟୁମଣ୍ଡଳ: 0.7042\n"
     ]
    }
   ],
   "source": [
    "# Example Odia words (edit as needed)\n",
    "odia_words = [\n",
    "    \"ଭଲ\",     # good\n",
    "    \"ମନ୍ଦ\",     # bad\n",
    "    \"ପ୍ରେମ\",   # love\n",
    "    \"ଘୃଣା\",    # hate\n",
    "    \"ଶିକ୍ଷା\",   # education\n",
    "    \"ଗ୍ରାମ\",   # village\n",
    "    \"ନଗର\",     # city\n",
    "    \"ପାଣି\",     # water\n",
    "    \"ଅଗ୍ନି\",    # fire\n",
    "    \"ବାୟୁ\"     # air\n",
    "]\n",
    "for word in odia_words:\n",
    "    if word in w2v_model.wv:\n",
    "        print(f'Words similar to {word}:')\n",
    "        for sim_word, score in w2v_model.wv.most_similar(word, topn=5):\n",
    "            print(f'  {sim_word}: {score:.4f}')\n",
    "    else:\n",
    "        print(f'{word} not in vocabulary.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to ଭଲ:\n",
      "  ଖରାପ: 0.5290\n",
      "  ଉତ୍ତମ: 0.4792\n",
      "  ଖୁସି: 0.4586\n",
      "  ନିଶ୍ଚିତ: 0.4577\n",
      "  ସହଜ: 0.4529\n",
      "Words similar to ମନ୍ଦ:\n",
      "  ଲାଗିବ୤: 0.6047\n",
      "  ଲାଗୁନାହିଁ: 0.5954\n",
      "  ପାଉଥିଲି: 0.5425\n",
      "  ପାଉଥାଏ: 0.5334\n",
      "  ଲାଗେନା: 0.5321\n",
      "Words similar to ପ୍ରେମ:\n",
      "  ପ୍ରେମର: 0.6476\n",
      "  ପ୍ରେମିକା: 0.6306\n",
      "  ଅନାବିଳ: 0.6268\n",
      "  ସ୍ନେହ: 0.6148\n",
      "  ପ୍ରୀତି: 0.6131\n",
      "Words similar to ଘୃଣା:\n",
      "  ଭୟ: 0.7651\n",
      "  ଉପହାସ: 0.7594\n",
      "  ଈର୍ଷା: 0.7435\n",
      "  ହତାଦର: 0.7241\n",
      "  ଶୋଷଣ: 0.7096\n",
      "Words similar to ଶିକ୍ଷା:\n",
      "  ଶିକ୍ଷ୍ୟା: 0.6527\n",
      "  ଉଚ୍ଚଶିକ୍ଷା: 0.6374\n",
      "  ତାଲିମ: 0.6238\n",
      "  ବିଦ୍ୟା: 0.5987\n",
      "  ଅଧ୍ୟୟନ: 0.5887\n",
      "Words similar to ଗ୍ରାମ:\n",
      "  ତହସିଲ: 0.7054\n",
      "  ବ୍ଲକ: 0.7006\n",
      "  ଘାଟି: 0.6615\n",
      "  ଗ୍ରାମରୁ: 0.6537\n",
      "  ଜିଲାର: 0.6533\n",
      "Words similar to ନଗର:\n",
      "  ବିହାରର: 0.7376\n",
      "  ଉତ୍ତରପ୍ରଦେଶ: 0.7351\n",
      "  କାଶ୍ମୀର: 0.7270\n",
      "  ମଥୁରା: 0.7248\n",
      "  ମଧ୍ୟପ୍ରଦେଶ: 0.7216\n",
      "Words similar to ପାଣି:\n",
      "  ପାଣିରେ: 0.6840\n",
      "  ଚିନି: 0.6542\n",
      "  ଘିଅ: 0.6522\n",
      "  କ୍ଷୀର: 0.6510\n",
      "  ଦୁଧ: 0.6498\n",
      "Words similar to ଅଗ୍ନି:\n",
      "  ସୂର୍ଯ୍ୟ: 0.6372\n",
      "  ଦେବତାଙ୍କର: 0.6263\n",
      "  ଗ୍ରହ: 0.6018\n",
      "  ରୋହିଣୀ: 0.6011\n",
      "  ଦାରୁବ୍ରହ୍ମ: 0.6007\n",
      "Words similar to ବାୟୁ:\n",
      "  ପ୍ରଦୂଷଣ: 0.7761\n",
      "  ଗ୍ୟାସ୍: 0.7189\n",
      "  ପ୍ରବାହ: 0.7130\n",
      "  ବାୟୁମଣ୍ଡଳ: 0.6747\n",
      "  ପ୍ରବାହର: 0.6708\n"
     ]
    }
   ],
   "source": [
    "for word in odia_words:\n",
    "    if word in w2vsg_model.wv:\n",
    "        print(f'Words similar to {word}:')\n",
    "        for sim_word, score in w2vsg_model.wv.most_similar(word, topn=5):\n",
    "            print(f'  {sim_word}: {score:.4f}')\n",
    "    else:\n",
    "        print(f'{word} not in vocabulary.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors (GloVe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to ଭଲ:\n",
      "  ଶାଲ: 0.3077\n",
      "  ଭାବରେ: 0.3075\n",
      "  ହୋଇଥାଏ: 0.3072\n",
      "  ଜରାରୋଗ: 0.2985\n",
      "  ଦକ୍ଷ: 0.2975\n",
      "Words similar to ମନ୍ଦ:\n",
      "  ଗ୍ରେଗୋରୀ: 0.2659\n",
      "  କୁମୁଦିନୀ: 0.2593\n",
      "  ବିରିୟାନୀ: 0.2561\n",
      "  ପନି: 0.2488\n",
      "  ଘଟନା: 0.2458\n",
      "Words similar to ପ୍ରେମ:\n",
      "  ଶାନ୍ତି: 0.2872\n",
      "  ୱେଲ୍: 0.2722\n",
      "  ୟୁ: 0.2615\n",
      "  କୁକୁରର: 0.2586\n",
      "  ଗୁଡ୍: 0.2558\n",
      "Words similar to ଘୃଣା:\n",
      "  ବୋହୁଙ୍କୁ: 0.2974\n",
      "  ଅନୁକୂଳ: 0.2802\n",
      "  ପରିବହନର: 0.2659\n",
      "  ଆବଶ୍ୟକତାକୁ: 0.2625\n",
      "  ଥକାପଣ: 0.2613\n",
      "Words similar to ଶିକ୍ଷା:\n",
      "  ନୃତ୍ୟ: 0.4376\n",
      "  ଉବ୍ଦେଶ୍ୟରେ: 0.4098\n",
      "  ଦର୍ଶନ: 0.3414\n",
      "  ଆହାରଣ: 0.3355\n",
      "  ପ୍ରଶିକ୍ଷଣ: 0.3240\n",
      "Words similar to ଗ୍ରାମ:\n",
      "  ପଞ୍ଚାଯତ: 0.3266\n",
      "  ପଞ୍ଚାୟତ: 0.3161\n",
      "  ପଞ୍ଚାୟତର: 0.3001\n",
      "  ସହର: 0.2956\n",
      "  ହାତଲେଖା: 0.2908\n",
      "Words similar to ନଗର:\n",
      "  କବିସୂର୍ଯ୍ୟ: 0.3220\n",
      "  ମୋନାରି: 0.2792\n",
      "  ହାଇସ୍କୁଲ୍: 0.2777\n",
      "  ବିରଚିତ: 0.2709\n",
      "  ମଉସା: 0.2639\n",
      "Words similar to ପାଣି:\n",
      "  ରକ୍: 0.3196\n",
      "  ଗାଧୋଇବା: 0.3051\n",
      "  ବୁହେ: 0.3007\n",
      "  କୁକର: 0.3005\n",
      "  ଝରେ: 0.2866\n",
      "Words similar to ଅଗ୍ନି:\n",
      "  ନିର୍ବାପକ: 0.3221\n",
      "  ଆଛା: 0.2892\n",
      "  ପ୍ରାକ୍: 0.2814\n",
      "  ପାଣି: 0.2780\n",
      "  ନିର୍ବାପିତ: 0.2771\n",
      "Words similar to ବାୟୁ:\n",
      "  ନାଟ୍ୟକାର: 0.3281\n",
      "  ସ୍ଟେମ: 0.2932\n",
      "  ବିଷଦୋଷ: 0.2800\n",
      "  ହରମୋନ: 0.2754\n",
      "  ଅଭିଯାନରେ: 0.2741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Reverse vocab for index to word\n",
    "glove_idx_to_word = {idx: word for word, idx in glove_vocab.items()}\n",
    "def get_glove_neighbors(word, topn=5):\n",
    "    if word not in glove_vocab:\n",
    "        print(f'{word} not in GloVe vocabulary.')\n",
    "        return\n",
    "    idx = glove_vocab[word]\n",
    "    vec = glove_embeddings[idx].reshape(1, -1)\n",
    "    sims = cosine_similarity(vec, glove_embeddings)[0]\n",
    "    best = np.argsort(-sims)[1:topn+1]\n",
    "    print(f'Words similar to {word}:')\n",
    "    for i in best:\n",
    "        print(f'  {glove_idx_to_word[i]}: {sims[i]:.4f}')\n",
    "# Example\n",
    "for word in odia_words:\n",
    "    get_glove_neighbors(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     w2v_vecs \u001b[38;5;241m=\u001b[39m [w2v_model\u001b[38;5;241m.\u001b[39mwv[w] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words_to_plot \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m w2v_model\u001b[38;5;241m.\u001b[39mwv]\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w2v_vecs:\n\u001b[1;32m---> 21\u001b[0m         \u001b[43mplot_tsne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw2v_vecs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords_to_plot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_to_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord2Vec t-SNE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[0;32m     23\u001b[0m     plot_tsne(glove_embeddings, glove_vocab, words_to_plot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGloVe t-SNE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mplot_tsne\u001b[1;34m(embeddings, vocab, words, title)\u001b[0m\n\u001b[0;32m      6\u001b[0m vecs \u001b[38;5;241m=\u001b[39m embeddings[idxs]\n\u001b[0;32m      7\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(reduced[:, \u001b[38;5;241m0\u001b[39m], reduced[:, \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32md:\\LLM_Chatbot\\llmvenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32md:\\LLM_Chatbot\\llmvenv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LLM_Chatbot\\llmvenv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1177\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m-> 1177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[1;32md:\\LLM_Chatbot\\llmvenv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:862\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_tsne(embeddings, vocab, words, title):\n",
    "    idxs = [vocab[w] for w in words if w in vocab]\n",
    "    vecs = embeddings[idxs]\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced = tsne.fit_transform(vecs)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced[:, 0], reduced[:, 1])\n",
    "    for i, word in enumerate(words):\n",
    "        if word in vocab:\n",
    "            plt.annotate(word, (reduced[i, 0], reduced[i, 1]), fontsize=12)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "# Example words for visualization\n",
    "words_to_plot = odia_words\n",
    "if 'w2v_model' in globals():\n",
    "    w2v_vecs = [w2v_model.wv[w] for w in words_to_plot if w in w2v_model.wv]\n",
    "    if w2v_vecs:\n",
    "        plot_tsne(np.array(w2v_vecs), {w: i for i, w in enumerate(words_to_plot)}, words_to_plot, 'Word2Vec t-SNE')\n",
    "if 'glove_embeddings' in globals():\n",
    "    plot_tsne(glove_embeddings, glove_vocab, words_to_plot, 'GloVe t-SNE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
